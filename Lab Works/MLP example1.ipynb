{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('a.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train=X[0:600,0:8]\n",
    "X_Test=X[600:,0:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Train=y[0:600]\n",
    "Y_Test=y[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-55f419f5e1b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6135 - acc: 0.4033\n",
      "Epoch 2/150\n",
      "600/600 [==============================] - 0s 107us/step - loss: 1.4413 - acc: 0.5600\n",
      "Epoch 3/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 1.0113 - acc: 0.6200\n",
      "Epoch 4/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.8796 - acc: 0.5933\n",
      "Epoch 5/150\n",
      "600/600 [==============================] - 0s 96us/step - loss: 0.8186 - acc: 0.6050\n",
      "Epoch 6/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.7548 - acc: 0.6233\n",
      "Epoch 7/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.7225 - acc: 0.6250\n",
      "Epoch 8/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.7138 - acc: 0.6217\n",
      "Epoch 9/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.6888 - acc: 0.6300\n",
      "Epoch 10/150\n",
      "600/600 [==============================] - 0s 98us/step - loss: 0.6746 - acc: 0.6417\n",
      "Epoch 11/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.6669 - acc: 0.6383\n",
      "Epoch 12/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.6463 - acc: 0.6567\n",
      "Epoch 13/150\n",
      "600/600 [==============================] - 0s 103us/step - loss: 0.6562 - acc: 0.6450\n",
      "Epoch 14/150\n",
      "600/600 [==============================] - 0s 117us/step - loss: 0.6476 - acc: 0.6633\n",
      "Epoch 15/150\n",
      "600/600 [==============================] - 0s 111us/step - loss: 0.6343 - acc: 0.6517\n",
      "Epoch 16/150\n",
      "600/600 [==============================] - 0s 133us/step - loss: 0.6353 - acc: 0.6650\n",
      "Epoch 17/150\n",
      "600/600 [==============================] - 0s 128us/step - loss: 0.6445 - acc: 0.6517\n",
      "Epoch 18/150\n",
      "600/600 [==============================] - 0s 108us/step - loss: 0.6415 - acc: 0.6483\n",
      "Epoch 19/150\n",
      "600/600 [==============================] - 0s 110us/step - loss: 0.6380 - acc: 0.6600\n",
      "Epoch 20/150\n",
      "600/600 [==============================] - 0s 111us/step - loss: 0.6316 - acc: 0.6517\n",
      "Epoch 21/150\n",
      "600/600 [==============================] - 0s 112us/step - loss: 0.6270 - acc: 0.6517\n",
      "Epoch 22/150\n",
      "600/600 [==============================] - 0s 101us/step - loss: 0.6348 - acc: 0.6483\n",
      "Epoch 23/150\n",
      "600/600 [==============================] - 0s 135us/step - loss: 0.6204 - acc: 0.6733\n",
      "Epoch 24/150\n",
      "600/600 [==============================] - 0s 105us/step - loss: 0.6314 - acc: 0.6700\n",
      "Epoch 25/150\n",
      "600/600 [==============================] - 0s 117us/step - loss: 0.6156 - acc: 0.6600\n",
      "Epoch 26/150\n",
      "600/600 [==============================] - 0s 98us/step - loss: 0.6160 - acc: 0.6833\n",
      "Epoch 27/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.6139 - acc: 0.6767\n",
      "Epoch 28/150\n",
      "600/600 [==============================] - 0s 100us/step - loss: 0.6044 - acc: 0.6850\n",
      "Epoch 29/150\n",
      "600/600 [==============================] - 0s 93us/step - loss: 0.6353 - acc: 0.6750\n",
      "Epoch 30/150\n",
      "600/600 [==============================] - 0s 113us/step - loss: 0.6164 - acc: 0.7050\n",
      "Epoch 31/150\n",
      "600/600 [==============================] - 0s 110us/step - loss: 0.6131 - acc: 0.6900\n",
      "Epoch 32/150\n",
      "600/600 [==============================] - 0s 111us/step - loss: 0.6122 - acc: 0.6883\n",
      "Epoch 33/150\n",
      "600/600 [==============================] - 0s 120us/step - loss: 0.6081 - acc: 0.6950\n",
      "Epoch 34/150\n",
      "600/600 [==============================] - 0s 112us/step - loss: 0.6104 - acc: 0.6800\n",
      "Epoch 35/150\n",
      "600/600 [==============================] - 0s 101us/step - loss: 0.6046 - acc: 0.6967\n",
      "Epoch 36/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5993 - acc: 0.6967\n",
      "Epoch 37/150\n",
      "600/600 [==============================] - 0s 120us/step - loss: 0.6115 - acc: 0.6850\n",
      "Epoch 38/150\n",
      "600/600 [==============================] - 0s 113us/step - loss: 0.5979 - acc: 0.7000\n",
      "Epoch 39/150\n",
      "600/600 [==============================] - 0s 148us/step - loss: 0.5960 - acc: 0.7067\n",
      "Epoch 40/150\n",
      "600/600 [==============================] - 0s 104us/step - loss: 0.5920 - acc: 0.7033\n",
      "Epoch 41/150\n",
      "600/600 [==============================] - 0s 119us/step - loss: 0.6050 - acc: 0.6933\n",
      "Epoch 42/150\n",
      "600/600 [==============================] - 0s 108us/step - loss: 0.5875 - acc: 0.7050\n",
      "Epoch 43/150\n",
      "600/600 [==============================] - 0s 117us/step - loss: 0.5827 - acc: 0.7283\n",
      "Epoch 44/150\n",
      "600/600 [==============================] - 0s 98us/step - loss: 0.5965 - acc: 0.7033\n",
      "Epoch 45/150\n",
      "600/600 [==============================] - 0s 106us/step - loss: 0.5896 - acc: 0.6967\n",
      "Epoch 46/150\n",
      "600/600 [==============================] - 0s 99us/step - loss: 0.5799 - acc: 0.7083\n",
      "Epoch 47/150\n",
      "600/600 [==============================] - 0s 107us/step - loss: 0.5882 - acc: 0.7100\n",
      "Epoch 48/150\n",
      "600/600 [==============================] - 0s 123us/step - loss: 0.5876 - acc: 0.7083\n",
      "Epoch 49/150\n",
      "600/600 [==============================] - 0s 110us/step - loss: 0.5775 - acc: 0.7117\n",
      "Epoch 50/150\n",
      "600/600 [==============================] - 0s 107us/step - loss: 0.5860 - acc: 0.7233\n",
      "Epoch 51/150\n",
      "600/600 [==============================] - 0s 105us/step - loss: 0.5774 - acc: 0.7017\n",
      "Epoch 52/150\n",
      "600/600 [==============================] - 0s 119us/step - loss: 0.5723 - acc: 0.7133\n",
      "Epoch 53/150\n",
      "600/600 [==============================] - 0s 117us/step - loss: 0.5784 - acc: 0.7233\n",
      "Epoch 54/150\n",
      "600/600 [==============================] - 0s 113us/step - loss: 0.5645 - acc: 0.7200\n",
      "Epoch 55/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5796 - acc: 0.7200\n",
      "Epoch 56/150\n",
      "600/600 [==============================] - 0s 97us/step - loss: 0.5784 - acc: 0.7117\n",
      "Epoch 57/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5694 - acc: 0.7300\n",
      "Epoch 58/150\n",
      "600/600 [==============================] - 0s 87us/step - loss: 0.5684 - acc: 0.7117\n",
      "Epoch 59/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5699 - acc: 0.7200\n",
      "Epoch 60/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5868 - acc: 0.7150\n",
      "Epoch 61/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5699 - acc: 0.7150\n",
      "Epoch 62/150\n",
      "600/600 [==============================] - 0s 92us/step - loss: 0.5674 - acc: 0.7150\n",
      "Epoch 63/150\n",
      "600/600 [==============================] - 0s 106us/step - loss: 0.5606 - acc: 0.7350\n",
      "Epoch 64/150\n",
      "600/600 [==============================] - 0s 122us/step - loss: 0.5692 - acc: 0.7150\n",
      "Epoch 65/150\n",
      "600/600 [==============================] - 0s 132us/step - loss: 0.5585 - acc: 0.7300\n",
      "Epoch 66/150\n",
      "600/600 [==============================] - 0s 126us/step - loss: 0.5593 - acc: 0.7300\n",
      "Epoch 67/150\n",
      "600/600 [==============================] - 0s 123us/step - loss: 0.5571 - acc: 0.7217\n",
      "Epoch 68/150\n",
      "600/600 [==============================] - 0s 100us/step - loss: 0.5607 - acc: 0.7317\n",
      "Epoch 69/150\n",
      "600/600 [==============================] - 0s 102us/step - loss: 0.5566 - acc: 0.7217\n",
      "Epoch 70/150\n",
      "600/600 [==============================] - 0s 123us/step - loss: 0.5539 - acc: 0.7433\n",
      "Epoch 71/150\n",
      "600/600 [==============================] - 0s 104us/step - loss: 0.5578 - acc: 0.7350\n",
      "Epoch 72/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5628 - acc: 0.7233\n",
      "Epoch 73/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5541 - acc: 0.7283\n",
      "Epoch 74/150\n",
      "600/600 [==============================] - 0s 121us/step - loss: 0.5572 - acc: 0.7233\n",
      "Epoch 75/150\n",
      "600/600 [==============================] - 0s 134us/step - loss: 0.5524 - acc: 0.7367\n",
      "Epoch 76/150\n",
      "600/600 [==============================] - 0s 116us/step - loss: 0.5539 - acc: 0.7283\n",
      "Epoch 77/150\n",
      "600/600 [==============================] - 0s 109us/step - loss: 0.5539 - acc: 0.7367\n",
      "Epoch 78/150\n",
      "600/600 [==============================] - 0s 101us/step - loss: 0.5481 - acc: 0.7433\n",
      "Epoch 79/150\n",
      "600/600 [==============================] - 0s 125us/step - loss: 0.5461 - acc: 0.7317\n",
      "Epoch 80/150\n",
      "600/600 [==============================] - 0s 116us/step - loss: 0.5504 - acc: 0.7250\n",
      "Epoch 81/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5486 - acc: 0.7183\n",
      "Epoch 82/150\n",
      "600/600 [==============================] - 0s 98us/step - loss: 0.5439 - acc: 0.7417\n",
      "Epoch 83/150\n",
      "600/600 [==============================] - 0s 105us/step - loss: 0.5460 - acc: 0.7350\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 108us/step - loss: 0.5438 - acc: 0.7250\n",
      "Epoch 85/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5462 - acc: 0.7300\n",
      "Epoch 86/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5387 - acc: 0.7467\n",
      "Epoch 87/150\n",
      "600/600 [==============================] - 0s 91us/step - loss: 0.5390 - acc: 0.7483\n",
      "Epoch 88/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5401 - acc: 0.7367\n",
      "Epoch 89/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5498 - acc: 0.7400\n",
      "Epoch 90/150\n",
      "600/600 [==============================] - 0s 95us/step - loss: 0.5437 - acc: 0.7383\n",
      "Epoch 91/150\n",
      "600/600 [==============================] - 0s 111us/step - loss: 0.5468 - acc: 0.7167\n",
      "Epoch 92/150\n",
      "600/600 [==============================] - 0s 93us/step - loss: 0.5415 - acc: 0.7333\n",
      "Epoch 93/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5349 - acc: 0.7400\n",
      "Epoch 94/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5377 - acc: 0.7417\n",
      "Epoch 95/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5347 - acc: 0.7383\n",
      "Epoch 96/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5358 - acc: 0.7417\n",
      "Epoch 97/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5419 - acc: 0.7333\n",
      "Epoch 98/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5374 - acc: 0.7167\n",
      "Epoch 99/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5317 - acc: 0.7383\n",
      "Epoch 100/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5285 - acc: 0.7383\n",
      "Epoch 101/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5327 - acc: 0.7467\n",
      "Epoch 102/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5395 - acc: 0.7483\n",
      "Epoch 103/150\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5324 - acc: 0.7417\n",
      "Epoch 104/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5321 - acc: 0.7567\n",
      "Epoch 105/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5279 - acc: 0.7350\n",
      "Epoch 106/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5351 - acc: 0.7433\n",
      "Epoch 107/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5291 - acc: 0.7300\n",
      "Epoch 108/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5408 - acc: 0.7417\n",
      "Epoch 109/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5248 - acc: 0.7517\n",
      "Epoch 110/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5332 - acc: 0.7433\n",
      "Epoch 111/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5244 - acc: 0.7500\n",
      "Epoch 112/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5284 - acc: 0.7500\n",
      "Epoch 113/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5218 - acc: 0.7600\n",
      "Epoch 114/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5273 - acc: 0.7500\n",
      "Epoch 115/150\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.5222 - acc: 0.7583\n",
      "Epoch 116/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5210 - acc: 0.7500\n",
      "Epoch 117/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5201 - acc: 0.7650\n",
      "Epoch 118/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5257 - acc: 0.7467\n",
      "Epoch 119/150\n",
      "600/600 [==============================] - 0s 92us/step - loss: 0.5200 - acc: 0.7567\n",
      "Epoch 120/150\n",
      "600/600 [==============================] - 0s 93us/step - loss: 0.5206 - acc: 0.7450\n",
      "Epoch 121/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5141 - acc: 0.7567\n",
      "Epoch 122/150\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5178 - acc: 0.7517\n",
      "Epoch 123/150\n",
      "600/600 [==============================] - 0s 84us/step - loss: 0.5157 - acc: 0.7633\n",
      "Epoch 124/150\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5192 - acc: 0.7617\n",
      "Epoch 125/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5182 - acc: 0.7567\n",
      "Epoch 126/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5166 - acc: 0.7450\n",
      "Epoch 127/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5114 - acc: 0.7567\n",
      "Epoch 128/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5177 - acc: 0.7517\n",
      "Epoch 129/150\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.5194 - acc: 0.7733\n",
      "Epoch 130/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5148 - acc: 0.7517\n",
      "Epoch 131/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5195 - acc: 0.7383\n",
      "Epoch 132/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5186 - acc: 0.7583\n",
      "Epoch 133/150\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5138 - acc: 0.7617\n",
      "Epoch 134/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5105 - acc: 0.7600\n",
      "Epoch 135/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5171 - acc: 0.7533\n",
      "Epoch 136/150\n",
      "600/600 [==============================] - 0s 82us/step - loss: 0.5116 - acc: 0.7567\n",
      "Epoch 137/150\n",
      "600/600 [==============================] - 0s 81us/step - loss: 0.5138 - acc: 0.7450\n",
      "Epoch 138/150\n",
      "600/600 [==============================] - 0s 85us/step - loss: 0.5140 - acc: 0.7483\n",
      "Epoch 139/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5066 - acc: 0.7583\n",
      "Epoch 140/150\n",
      "600/600 [==============================] - 0s 87us/step - loss: 0.5067 - acc: 0.7733\n",
      "Epoch 141/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5163 - acc: 0.7517\n",
      "Epoch 142/150\n",
      "600/600 [==============================] - 0s 87us/step - loss: 0.5083 - acc: 0.7600\n",
      "Epoch 143/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5188 - acc: 0.7517\n",
      "Epoch 144/150\n",
      "600/600 [==============================] - 0s 86us/step - loss: 0.5081 - acc: 0.7700\n",
      "Epoch 145/150\n",
      "600/600 [==============================] - 0s 96us/step - loss: 0.5061 - acc: 0.7550\n",
      "Epoch 146/150\n",
      "600/600 [==============================] - 0s 102us/step - loss: 0.5069 - acc: 0.7667\n",
      "Epoch 147/150\n",
      "600/600 [==============================] - 0s 88us/step - loss: 0.5095 - acc: 0.7550\n",
      "Epoch 148/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5085 - acc: 0.7533\n",
      "Epoch 149/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5042 - acc: 0.7617\n",
      "Epoch 150/150\n",
      "600/600 [==============================] - 0s 83us/step - loss: 0.5130 - acc: 0.7600\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "history=model.fit(X_Train, Y_Train, epochs=150, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 0s 245us/step\n",
      "Accuracy: 70.83\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_Test, Y_Test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
